{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
    "import os\n",
    "import operator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.io import loadmat\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "df1 = pd.read_csv(r'final_dataset.CSV',header = None)\n",
    "data = df1.values\n",
    "random.shuffle(data)\n",
    "x=data[:,0:1000]\n",
    "y=data[:,1000:1001]\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
    "x_train, x_valid , y_train , y_valid = train_test_split(x_train,y_train,test_size=0.3)\n",
    "nb_classes = len(np.unique(np.concatenate((y_train, y_test), axis=0)))\n",
    "# print(nb_classes)\n",
    "# print(y.shape)\n",
    "# print(y)\n",
    "# print(x.shape)\n",
    "\n",
    "# transform the labels from integers to one hot vectors\n",
    "enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
    "enc.fit(np.concatenate((y_train, y_test), axis=0).reshape(-1, 1))\n",
    "y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "y_valid = enc.transform(y_valid.reshape(-1, 1)).toarray()\n",
    "\n",
    "# save orignal y because later we will use binary\n",
    "\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "if len(x_train.shape) == 2:  # if univariate\n",
    "    # add a dimension to make it multivariate with one dimension \n",
    "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "    x_valid = x_valid.reshape((x_valid.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "input_shape = x_train.shape[1:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1000, 1)\n",
      "(None, 1000, 64)\n",
      "(None, 1000, 64)\n",
      "(None, 1000, 64)\n",
      "(None, 1000, 64)\n",
      "(None, 1000, 64)\n",
      "(None, 1000, 64)\n",
      "(None, 6)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 1000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 1000, 64)     576         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 1000, 64)    256         ['conv1d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 1000, 64)     0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 1000, 64)     20544       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 1000, 64)    256         ['conv1d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 1000, 64)     0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 1000, 64)     128         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 1000, 64)     12352       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 1000, 64)    256         ['conv1d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 1000, 64)    256         ['conv1d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 1000, 64)     0           ['batch_normalization_39[0][0]', \n",
      "                                                                  'batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 1000, 64)     0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 1000, 128)    65664       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 1000, 128)   512         ['conv1d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 1000, 128)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 1000, 128)    82048       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 1000, 128)   512         ['conv1d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 1000, 128)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 1000, 64)     24640       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 1000, 64)    256         ['activation_26[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 1000, 64)    256         ['conv1d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 1000, 64)     0           ['batch_normalization_43[0][0]', \n",
      "                                                                  'batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 1000, 64)     0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 64)          0           ['activation_29[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 6)            390         ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 6)            42          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 208,944\n",
      "Trainable params: 207,664\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input_size = (15483,1001)\n",
    "# inputs = keras.layers.Input(input_size)\n",
    "n_feature_maps = 64\n",
    "\n",
    "inputs = keras.layers.Input(input_shape)\n",
    "print(inputs.shape)\n",
    "\n",
    "# BLOCK 1\n",
    "\n",
    "conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(inputs)\n",
    "conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "print(conv_x.shape)\n",
    "\n",
    "conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n",
    "conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "print(conv_y.shape)\n",
    "\n",
    "conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n",
    "conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "print(conv_z.shape)\n",
    "\n",
    "# expand channels for the sum\n",
    "shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(inputs)\n",
    "shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "print(shortcut_y.shape)\n",
    "\n",
    "output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
    "output_block_1 = keras.layers.Activation('relu')(output_block_1)\n",
    "print(output_block_1.shape)\n",
    "\n",
    "# BLOCK 2\n",
    "\n",
    "# conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
    "# conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "# conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "# print(conv_x.shape)\n",
    "\n",
    "# conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "# conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "# conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "# print(conv_y.shape)\n",
    "\n",
    "# conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "# conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "# print(conv_z.shape)\n",
    "\n",
    "# # expand channels for the sum\n",
    "# shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
    "# shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "# print(shortcut_y.shape)\n",
    "\n",
    "# output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
    "# output_block_2 = keras.layers.Activation('relu')(output_block_2)\n",
    "# print(output_block_2.shape)\n",
    "\n",
    "# BLOCK 3\n",
    "\n",
    "conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
    "conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "conv_z = keras.layers.Conv1D(filters=n_feature_maps , kernel_size=3, padding='same')(conv_y)\n",
    "conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "# no need to expand channels because they are equal\n",
    "shortcut_y = keras.layers.BatchNormalization()(output_block_1)\n",
    "\n",
    "\n",
    "output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
    "output_block_3 = keras.layers.Activation('relu')(output_block_3)\n",
    "print(output_block_3.shape)\n",
    "\n",
    "# FINAL\n",
    "\n",
    "gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
    "\n",
    "output_layer1 = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n",
    "output_layer = keras.layers.Dense(nb_classes, activation='softmax')(output_layer1)\n",
    "\n",
    "print(output_layer.shape)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1000, 1)\n",
      "(None, 1000, 64)\n",
      "(None, 1000, 64)\n",
      "(None, 1000, 64)\n",
      "(None, 1000, 64)\n",
      "(None, 1000, 64)\n",
      "(None, 1000, 128)\n",
      "(None, 1000, 128)\n",
      "(None, 1000, 128)\n",
      "(None, 1000, 128)\n",
      "(None, 1000, 128)\n",
      "(None, 1000, 128)\n",
      "(None, 6)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1000, 64)     576         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1000, 64)    256         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1000, 64)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 1000, 64)     20544       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 1000, 64)    256         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 1000, 64)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 1000, 64)     128         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 1000, 64)     12352       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 1000, 64)    256         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 1000, 64)    256         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 1000, 64)     0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 1000, 64)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 1000, 128)    65664       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 1000, 128)   512         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 1000, 128)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 1000, 128)    82048       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 1000, 128)   512         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 1000, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 1000, 128)    8320        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 1000, 128)    49280       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 1000, 128)   512         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 1000, 128)   512         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 1000, 128)    0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 1000, 128)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 1000, 128)    131200      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1000, 128)   512         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 1000, 128)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 1000, 128)    82048       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 1000, 128)   512         ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 1000, 128)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 1000, 128)    49280       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 1000, 128)   512         ['activation_5[0][0]']           \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 1000, 128)   512         ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 1000, 128)    0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 1000, 128)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['activation_8[0][0]']           \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            774         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 507,334\n",
      "Trainable params: 504,774\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''# input_size = (15483,1001)\n",
    "# inputs = keras.layers.Input(input_size)\n",
    "n_feature_maps = 64\n",
    "\n",
    "inputs = keras.layers.Input(input_shape)\n",
    "print(inputs.shape)\n",
    "\n",
    "# BLOCK 1\n",
    "\n",
    "conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(inputs)\n",
    "conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "print(conv_x.shape)\n",
    "\n",
    "conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n",
    "conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "print(conv_y.shape)\n",
    "\n",
    "conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n",
    "conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "print(conv_z.shape)\n",
    "\n",
    "# expand channels for the sum\n",
    "shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(inputs)\n",
    "shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "print(shortcut_y.shape)\n",
    "\n",
    "output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
    "output_block_1 = keras.layers.Activation('relu')(output_block_1)\n",
    "print(output_block_1.shape)\n",
    "\n",
    "# BLOCK 2\n",
    "\n",
    "conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
    "conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "print(conv_x.shape)\n",
    "\n",
    "conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "print(conv_y.shape)\n",
    "\n",
    "conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "print(conv_z.shape)\n",
    "\n",
    "# expand channels for the sum\n",
    "shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
    "shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "print(shortcut_y.shape)\n",
    "\n",
    "output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
    "output_block_2 = keras.layers.Activation('relu')(output_block_2)\n",
    "print(output_block_2.shape)\n",
    "\n",
    "# BLOCK 3\n",
    "\n",
    "conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_2)\n",
    "conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "# no need to expand channels because they are equal\n",
    "shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n",
    "\n",
    "output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
    "output_block_3 = keras.layers.Activation('relu')(output_block_3)\n",
    "print(output_block_3.shape)\n",
    "\n",
    "# FINAL\n",
    "\n",
    "gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
    "\n",
    "output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n",
    "print(output_layer.shape)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "\n",
    "file_path =  'best_model.hdf5'\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n",
    "                                                    save_best_only=True)\n",
    "\n",
    "callbacks = [reduce_lr, model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 151s 2s/step - loss: 1.5851 - accuracy: 0.3778 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.4580 - accuracy: 0.4862 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 134s 1s/step - loss: 1.3253 - accuracy: 0.5542 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 132s 1s/step - loss: 1.2630 - accuracy: 0.5882 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 133s 1s/step - loss: 1.2062 - accuracy: 0.6075 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 124s 1s/step - loss: 1.1505 - accuracy: 0.6171 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 121s 1s/step - loss: 1.0993 - accuracy: 0.6246 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 122s 1s/step - loss: 1.0520 - accuracy: 0.6462 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 122s 1s/step - loss: 1.0007 - accuracy: 0.6618 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 123s 1s/step - loss: 0.9631 - accuracy: 0.6718 - lr: 0.0010\n",
      "69/69 [==============================] - 7s 98ms/step - loss: 1.9783 - accuracy: 0.3065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.978264331817627, 0.30646631121635437]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "nb_epochs = 10\n",
    "mini_batch_size = int(min(x_train.shape[0] / 10, batch_size))\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=nb_epochs,\n",
    "                        verbose=1, callbacks=callbacks)\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: final_model\\assets\n",
      "69/69 [==============================] - 17s 246ms/step - loss: 6.2329 - accuracy: 0.2131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.232907772064209, 0.21311475336551666]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('final_model')\n",
    "'''\n",
    "batch_size = 64\n",
    "nb_epochs = 50\n",
    "mini_batch_size = int(min(x_train.shape[0] / 10, batch_size))\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=nb_epochs,\n",
    "                        verbose=1, callbacks=callbacks)'''\n",
    "model.evaluate(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a0cd66df47b1766b6e57c3bccbe617af2527ac4c799c954190befd7df80af49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
